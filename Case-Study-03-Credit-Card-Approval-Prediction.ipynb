{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Case Study 03 - Credit Card Approval Prediction\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Introduction \n",
    "\n",
    "In this case study, we use the **Credit Card Approval Data Set** from [UCI Machine Learning Repository](http://archive.ics.uci.edu/ml/datasets/credit+approval) to build a machine learning classification model that predicts if the credit card application of an applicant will be accepted, based on several key factors available in the data set. \n",
    "\n",
    "As mentioned in the above website, the data set has been anonymized due to confidentiality of the data. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Basic Insight of Data\n",
    "\n",
    "#### Loading data and creating a dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "dc": {
     "key": "3"
    },
    "tags": [
     "sample_code"
    ]
   },
   "outputs": [],
   "source": [
    "# Import pandas\n",
    "import pandas as pd\n",
    "\n",
    "# Load dataset\n",
    "cc_apps = pd.read_csv( \"cc_approvals.data\", header = None)\n",
    "\n",
    "# Inspect data\n",
    "cc_apps.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(\"The dataframe has {} datapoints and {} columns.\".format(*cc_apps.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Remark on column names\n",
    "\n",
    "As mentioned above, the data set has been anonymized due to confidentiality of the data. To have a better idea about meaning of data, we list the most important features that are taken into account in processing a credit card application. These are:\n",
    "\n",
    "- Male\n",
    "- Age\n",
    "- Debt \n",
    "- Married       \n",
    "- BankCustomer \n",
    "- EducationLevel\n",
    "- Ethnicity \n",
    "- YearsEmployed\n",
    "- PriorDefault  \n",
    "- Employed      \n",
    "- CreditScore   \n",
    "- DriversLicense\n",
    "- Citizen   \n",
    "- ZipCode      \n",
    "- Income      \n",
    "- Approved\n",
    "\n",
    "For further information, you may want to refer to [here](http://rstudio-pubs-static.s3.amazonaws.com/73039_9946de135c0a49daa7a0a9eda4a67a72.html). Before inspecting the dataframe further, let's rename the columns so that our dataframe be in a better form."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create headers list\n",
    "headers = [\n",
    "\"Male\",\n",
    "\"Age\",\n",
    "\"Debt\", \n",
    "\"Married\",       \n",
    "\"BankCustomer\", \n",
    "\"EducationLevel\",\n",
    "\"Ethnicity\", \n",
    "\"YearsEmployed\",\n",
    "\"PriorDefault\",  \n",
    "\"Employed\",      \n",
    "\"CreditScore\",   \n",
    "\"DriversLicense\",\n",
    "\"Citizen\",   \n",
    "\"ZipCode\",       \n",
    "\"Income\",      \n",
    "\"Approved\"\n",
    "]\n",
    "\n",
    "cc_apps.columns = headers\n",
    "cc_apps.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remember that the values of the data sets have been anonymized by the data set provider. So, we weren't surprised for example with 'float' datatype in the 'Age' column. Note also that since features like `DriversLicense` and `ZipCode` are not as important as the other features in the dataset for predicting credit card approvals, we can drop them to design our machine learning model with the best set of features. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the features 'DriversLicense' and 'ZipCode'\n",
    "cc_apps.drop(['DriversLicense', 'ZipCode'], axis = 1, inplace = True)\n",
    "cc_apps.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a summary of dataframe\n",
    "cc_apps.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# a summary statistics of numerical variables\n",
    "cc_apps.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Preprocessing\n",
    "\n",
    "### 3.1 Identifying missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "dc": {
     "key": "10"
    },
    "tags": [
     "sample_code"
    ]
   },
   "outputs": [],
   "source": [
    "# any missing values?\n",
    "if cc_apps.isnull().values.any():\n",
    "    print(\"YES\")\n",
    "else:\n",
    "    print(\"Nothing detected!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems that there are no 'NaN' missing values. However, we need to make sure there is no other type of missing values in the dataframe. Let's examine the dataframe further."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Inspect missing values\n",
    "cc_apps.iloc[80:90]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, there are some missing values labled with \"?\". We replace them with 'NaN' to be able to identify all variables with missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "dc": {
     "key": "17"
    },
    "run_control": {
     "frozen": false
    },
    "scrolled": true,
    "tags": [
     "context"
    ]
   },
   "outputs": [],
   "source": [
    "# Import numpy\n",
    "import numpy as np\n",
    "\n",
    "# replace \"?\" with NaN\n",
    "cc_apps.replace(\"?\", np.nan, inplace = True)\n",
    "\n",
    "# check the dataframe again\n",
    "cc_apps.iloc[80:90]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we can find the total number of missing values in the dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Total number of missing values\n",
    "tot = cc_apps.isnull().sum().sum()\n",
    "print(\"The are totally {} missing values in the dataframe.\".format(tot))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can find the missing values by column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Missing values by column\n",
    "missing_condition = cc_apps.isnull().sum()\n",
    "\n",
    "# number of column with missing values\n",
    "column_null = missing_condition[missing_condition > 0]\n",
    "\n",
    "print(\"There are {} features with missing values.\".format(column_null.count()), \"\\n\")\n",
    "\n",
    "# missing values by column sorted descending\n",
    "column_null.sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, the first column is the column number. Most of missing values are in the 'Age' and 'Male' columns. Notice that all of these features are categorical."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Imputing missing data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use data discription to find out the meaning of these missing values. We proceed imputing missing values. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Replacing missing values by mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Impute the missing values with mean imputation\n",
    "cc_apps.fillna(cc_apps.mean(), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count the number of NaNs in the dataset to verify\n",
    "cc_apps.isnull().sum().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, as identified above, all missing values are in the columns with of categorical variables.\n",
    "\n",
    "#### Replacing missing values by frequency (mode)\n",
    "\n",
    "For categorical variables, we replace the missing values by the most frequent value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterate over each column of cc_apps\n",
    "for col in cc_apps.columns.values:\n",
    "    # Check if the column is of object type\n",
    "    if cc_apps[col].dtypes == 'object':\n",
    "        # Impute with the most frequent value\n",
    "        cc_apps = cc_apps.fillna(cc_apps[col].value_counts().index[0])\n",
    "\n",
    "# Count the number of NaNs in the dataset and print the counts to verify\n",
    "cc_apps.isnull().sum().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "dc": {
     "key": "24"
    },
    "run_control": {
     "frozen": false
    },
    "tags": [
     "context"
    ]
   },
   "source": [
    "### 3.3 Encoding categorical variables\n",
    "\n",
    "We need to convert categorical to numerical variables. We use [Label Encoder](http://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.LabelEncoder.html) technique. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "dc": {
     "key": "38"
    },
    "tags": [
     "sample_code"
    ]
   },
   "outputs": [],
   "source": [
    "# Import LabelEncoder\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Instantiate LabelEncoder\n",
    "le = LabelEncoder()\n",
    "\n",
    "# Iterate over all the values of each column and extract their dtypes\n",
    "for col in cc_apps.columns.values:\n",
    "    # Compare if the dtype is object\n",
    "    if cc_apps[col].dtypes == 'object':\n",
    "    # Use LabelEncoder to do the numeric transformation\n",
    "        cc_apps[col] = le.fit_transform(cc_apps[col])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "dc": {
     "key": "24"
    },
    "run_control": {
     "frozen": false
    },
    "tags": [
     "context"
    ]
   },
   "source": [
    "### 3.4 Splitting the dataset into train and test sets\n",
    "\n",
    "Now, we will split our data into train set and test set to prepare our data for training and testing. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "dc": {
     "key": "45"
    },
    "tags": [
     "sample_code"
    ]
   },
   "outputs": [],
   "source": [
    "# Import train_test_split\n",
    "from sklearn.model_selection import train_test_split  \n",
    "\n",
    "#convert the dataframe to a numpy array\n",
    "cc_apps = cc_apps.values\n",
    "\n",
    "# Segregate features and labels into separate variables\n",
    "X, y = cc_apps[:,0:-1] , cc_apps[:,-1]\n",
    "\n",
    "# Split into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = 42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "dc": {
     "key": "52"
    },
    "run_control": {
     "frozen": false
    },
    "tags": [
     "context"
    ]
   },
   "source": [
    "### 3.5 Scaling\n",
    "\n",
    "We use `MinMaxScaler` to scale the data to the range of numbers between 0 and 1, inclusive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "dc": {
     "key": "52"
    },
    "tags": [
     "sample_code"
    ]
   },
   "outputs": [],
   "source": [
    "# Import MinMaxScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Instantiate MinMaxScaler and use it to rescale X_train and X_test\n",
    "scaler = MinMaxScaler(feature_range = (0, 1))\n",
    "rescaledX_train = scaler.fit_transform(X_train)\n",
    "rescaledX_test = scaler.fit_transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, our data is ready for modelling."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "dc": {
     "key": "59"
    },
    "run_control": {
     "frozen": false
    },
    "tags": [
     "context"
    ]
   },
   "source": [
    "## 4. Modeling \n",
    "\n",
    "Predicting if a credit card application will be approved or not is indeed a classification task. According to [UCI](http://archive.ics.uci.edu/ml/machine-learning-databases/credit-screening/crx.names), our dataset contains more \"denial\" instances than \"approval\". Specifically, out of 690 applications, 383 (55.5%) applications were denied and 307 (44.5%) applications were approved. This gives us a benchmark. A good machine learning model should be able to accurately predict the status of the applications with respect to these statistics.\n",
    "\n",
    "We fit a logistic regression model to the train set to perform the classification task. This is because generalised linear models (and in particular, logistic regression) perform well in cases where there are correlations between predictor variables. Here, we assume that this is the case and the features that affect the credit card approval decision process correlated with each other, which is acceptable intuitively and can be confirmed computationally. \n",
    "\n",
    "We start the modeling with a Logistic Regression algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "dc": {
     "key": "59"
    },
    "tags": [
     "sample_code"
    ]
   },
   "outputs": [],
   "source": [
    "# Import LogisticRegression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Instantiate a LogisticRegression classifier with default parameter values\n",
    "logreg = LogisticRegression()\n",
    "\n",
    "# Fit logreg to the train set\n",
    "logreg.fit(rescaledX_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "dc": {
     "key": "66"
    },
    "run_control": {
     "frozen": false
    },
    "tags": [
     "context"
    ]
   },
   "source": [
    "## 5. Prediction and its performance\n",
    "\n",
    "To see how well our model performs, we evaluate its performance on the test set, using the model's `acuracy score` and `confusion matrix`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "dc": {
     "key": "66"
    },
    "scrolled": true,
    "tags": [
     "sample_code"
    ]
   },
   "outputs": [],
   "source": [
    "# Import confusion_matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# Use logreg to predict instances from the test set and store it\n",
    "y_pred = logreg.predict(rescaledX_test)\n",
    "\n",
    "# Get the accuracy score of logreg model and print it\n",
    "print(\"Accuracy of logistic regression classifier: \", logreg.score(rescaledX_test, y_test))\n",
    "\n",
    "# The confusion matrix of the logreg model\n",
    "confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the confusion matrix, the first diagonal element, 87, denotes the **true negatives** or the number of negative instances (denied applications) that our model predicted correctly. The next diagonal element, 87, denotes the **true positives** or the number of positive instances (approved applications) that the model predicted correctly. The off-diagonal elements, 10 + 23, represent the total number of wrong predictions, positive or negative."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "dc": {
     "key": "73"
    },
    "run_control": {
     "frozen": false
    },
    "tags": [
     "context"
    ]
   },
   "source": [
    "## 6. Grid searching\n",
    "\n",
    "The performance of our model was very good with an accuracy score of about 84%. The `Grid Search` is a scikit-learn technique that tunes the algorithm's parameters to improve the performance of the model. Here we grid search only over the following two among [parameters of logistic regression](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html). \n",
    "\n",
    "- tol\n",
    "- max_iter\n",
    "\n",
    "Let's first define the grid of hyperparameter values and convert them to a dictionary which is the expected format of input parameter in `GridSearchCV()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "dc": {
     "key": "73"
    },
    "tags": [
     "sample_code"
    ]
   },
   "outputs": [],
   "source": [
    "# Import GridSearchCV\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Define the grid of values for tol and max_iter\n",
    "tol = [0.01, 0.001 ,0.0001]\n",
    "max_iter = [100, 150, 200]\n",
    "\n",
    "# Create a dictionary where tol and max_iter are keys and the lists of their values are corresponding values\n",
    "param_grid = dict(tol=tol, max_iter=max_iter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "dc": {
     "key": "80"
    },
    "run_control": {
     "frozen": false
    },
    "tags": [
     "context"
    ]
   },
   "source": [
    "### 6.1 Selecting best performing model\n",
    "\n",
    "To begin the grid search and find out which values perform best, we need to create an instance of `GridSearchCV()` with already created instance `logreg` of our logistic regression model. We also instruct `GridSearchCV()` to perform a 5-fold cross validation. Note that we pass `X` (scaled version) and `y` as fit parameters rather than passing train and test sets. Finally, we store the best-achieved score and the respective best parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "dc": {
     "key": "80"
    },
    "tags": [
     "sample_code"
    ]
   },
   "outputs": [],
   "source": [
    "# Instantiate GridSearchCV with the required parameters\n",
    "grid_model = GridSearchCV(estimator = logreg, param_grid = param_grid, cv = 5)\n",
    "\n",
    "# Use scaler to rescale X and assign it to rescaledX\n",
    "rescaledX = scaler.fit_transform(X)\n",
    "\n",
    "# Fit data to grid_model\n",
    "grid_model_result = grid_model.fit(rescaledX, y)\n",
    "\n",
    "# Summarize results: store the best-achieved score and parameters \n",
    "best_score, best_params = grid_model_result.best_score_, grid_model_result.best_params_\n",
    "print(\"Best: %f using %s\" % (best_score, best_params))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\" role=\"alert\" style=\"margin-top: 1px\">\n",
    "\n",
    "## This notebook has been created by [ALIREZA RAFIYI](www.linkedin.com/in/alireza-rafiyi) and last updated on June 2020.  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
